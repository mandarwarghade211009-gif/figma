#!/usr/bin/env python3
"""
Optimized Figma UI Extractor & Angular Code Processor
Minimal metadata extraction for token-efficient AI agent processing
"""

import streamlit as st
import requests
import json
import re
import datetime
from io import BytesIO
from typing import Any, Dict, List, Set, Tuple, Optional
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph
from reportlab.lib.units import inch
import copy

# -----------------------------------------------------
# PROFESSIONAL THEMING
# -----------------------------------------------------
def apply_professional_styling():
    """Apply professional, government-style CSS theme"""
    st.markdown("""
    <style>
    /* Your original styling - keeping unchanged */
    </style>
    """, unsafe_allow_html=True)

st.set_page_config(
    page_title="Figma UI Extractor | Optimized Edition",
    page_icon="üé®",
    layout="wide",
    initial_sidebar_state="expanded"
)

apply_professional_styling()

# -----------------------------------------------------
# UTILITY HELPERS - OPTIMIZED
# -----------------------------------------------------

def build_headers(token: str) -> Dict[str, str]:
    return {"Accept": "application/json", "X-Figma-Token": token}

def chunked(lst: List[str], n: int):
    for i in range(0, len(lst), n):
        yield lst[i:i+n]

def to_hex(color: Dict[str, Any]) -> str:
    """Convert Figma color to compact hex format"""
    try:
        r = int(float(color.get("r", 0)) * 255)
        g = int(float(color.get("g", 0)) * 255)
        b = int(float(color.get("b", 0)) * 255)
        a = float(color.get("a", color.get("opacity", 1)))
        if a < 1:
            return f"#{r:02x}{g:02x}{b:02x}{int(a*255):02x}"
        return f"#{r:02x}{g:02x}{b:02x}"
    except:
        return "#000000"

def is_visible(node: Dict[str, Any]) -> bool:
    v = node.get("visible")
    o = node.get("opacity", 1)
    return (True if v is None else bool(v)) and o > 0

def filter_invisible_nodes(node: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    if not is_visible(node):
        return None
    if "children" in node:
        filtered = []
        for c in node["children"]:
            if isinstance(c, dict):
                fc = filter_invisible_nodes(c)
                if fc:
                    filtered.append(fc)
        node["children"] = filtered
    return node

# -------------------------
# FIGMA API - OPTIMIZED
# -------------------------

def fetch_figma_nodes(file_key: str, node_ids: str, token: str, timeout: int = 60) -> Dict[str, Any]:
    """Fetch nodes with minimal payload"""
    headers = build_headers(token)
    url = f"https://api.figma.com/v1/files/{file_key}/nodes"
    params = {"ids": node_ids, "depth": 99} if node_ids else {"depth": 99}
    r = requests.get(url, headers=headers, params=params, timeout=timeout)
    if not r.ok:
        raise RuntimeError(f"Figma API error {r.status_code}: {r.text}")
    data = r.json()
    
    if isinstance(data.get("nodes"), dict):
        for k, v in list(data["nodes"].items()):
            doc = v.get("document")
            if isinstance(doc, dict):
                data["nodes"][k]["document"] = filter_invisible_nodes(doc)
    elif isinstance(data.get("document"), dict):
        data["document"] = filter_invisible_nodes(data["document"])
    return data

def walk_nodes_collect_images_and_ids(nodes_payload: Dict[str, Any]) -> Tuple[Set[str], List[str]]:
    """Collect only image refs and critical node IDs"""
    image_refs: Set[str] = set()
    node_ids: List[str] = []

    def visit(n: Dict[str, Any]):
        if not isinstance(n, dict):
            return
        nid = n.get("id")
        ntype = (n.get("type") or "").upper()
        
        # Only collect IDs for semantic/visual nodes
        if nid and (ntype in ['TEXT', 'FRAME', 'COMPONENT', 'INSTANCE', 'RECTANGLE', 'GROUP', 'VECTOR'] 
                    or n.get("fills") or n.get("strokes")):
            node_ids.append(nid)
        
        # Collect image fills
        for f in n.get("fills", []) or []:
            if isinstance(f, dict) and f.get("type") == "IMAGE":
                ref = f.get("imageRef") or f.get("imageHash")
                if ref:
                    image_refs.add(ref)
        
        for c in n.get("children", []) or []:
            visit(c)

    if isinstance(nodes_payload.get("nodes"), dict):
        for entry in nodes_payload["nodes"].values():
            doc = entry.get("document")
            if isinstance(doc, dict):
                visit(doc)
    if isinstance(nodes_payload.get("document"), dict):
        visit(nodes_payload["document"])

    # De-duplicate
    seen = set()
    unique_ids = []
    for nid in node_ids:
        if nid not in seen:
            seen.add(nid)
            unique_ids.append(nid)

    return image_refs, unique_ids

def resolve_image_urls(file_key: str, image_refs: Set[str], token: str, timeout: int = 60) -> Dict[str, str]:
    """Resolve only fill images (skip renders to save tokens)"""
    headers = build_headers(token)
    fills_map: Dict[str, str] = {}
    try:
        if image_refs:
            fills_url = f"https://api.figma.com/v1/files/{file_key}/images"
            params = {"ids": ",".join(list(image_refs))}
            r = requests.get(fills_url, headers=headers, params=params, timeout=timeout)
            if r.ok:
                fills_map = r.json().get("images", {}) or {}
    except Exception:
        pass
    return {k: v for k, v in fills_map.items() if k in image_refs}

def merge_urls_into_nodes(nodes_payload: Dict[str, Any], fills_map: Dict[str, str]) -> Dict[str, Any]:
    """Inject image URLs into nodes"""
    merged = copy.deepcopy(nodes_payload)

    def inject(n: Dict[str, Any]):
        if not isinstance(n, dict):
            return
        for f in n.get("fills", []) or []:
            if isinstance(f, dict) and f.get("type") == "IMAGE":
                ref = f.get("imageRef") or f.get("imageHash")
                if ref and ref in fills_map:
                    n["image_url"] = fills_map[ref]
                    break
        for c in n.get("children", []) or []:
            inject(c)

    if isinstance(merged.get("nodes"), dict):
        for entry in merged["nodes"].values():
            doc = entry.get("document")
            if isinstance(doc, dict):
                inject(doc)
    if isinstance(merged.get("document"), dict):
        inject(merged["document"])
    return merged

# -------------------------
# OPTIMIZED EXTRACTION - ESSENTIAL ONLY
# -------------------------

def extract_essential_bounds(node: Dict[str, Any]) -> Optional[Dict[str, float]]:
    """Extract only x, y, w, h - rounded to 2 decimals"""
    box = node.get("absoluteBoundingBox")
    if isinstance(box, dict):
        try:
            return {
                "x": round(float(box["x"]), 2),
                "y": round(float(box["y"]), 2),
                "w": round(float(box["width"]), 2),
                "h": round(float(box["height"]), 2)
            }
        except:
            return None
    return None

def extract_essential_layout(node: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """Extract only critical layout properties for Angular flex/grid"""
    layout = {}
    
    # Auto-layout essentials
    if node.get('layoutMode'):
        layout['mode'] = node['layoutMode']  # AUTO, HORIZONTAL, VERTICAL
    if 'itemSpacing' in node:
        layout['gap'] = round(float(node['itemSpacing']), 1)
    
    # Padding (compact)
    p = {}
    if 'paddingLeft' in node: p['l'] = round(float(node['paddingLeft']), 1)
    if 'paddingRight' in node: p['r'] = round(float(node['paddingRight']), 1)
    if 'paddingTop' in node: p['t'] = round(float(node['paddingTop']), 1)
    if 'paddingBottom' in node: p['b'] = round(float(node['paddingBottom']), 1)
    if p: layout['pad'] = p
    
    # Alignment
    if node.get('primaryAxisAlignItems'):
        layout['alignMain'] = node['primaryAxisAlignItems']
    if node.get('counterAxisAlignItems'):
        layout['alignCross'] = node['counterAxisAlignItems']
    
    # Sizing
    if node.get('layoutSizingHorizontal'):
        layout['sizeX'] = node['layoutSizingHorizontal']
    if node.get('layoutSizingVertical'):
        layout['sizeY'] = node['layoutSizingVertical']
    
    return layout if layout else None

def extract_essential_style(node: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """Extract only visible styling - compact format"""
    style = {}
    
    # Background fill (first solid only)
    fills = node.get("fills", [])
    if isinstance(fills, list) and len(fills) > 0:
        for f in fills:
            if isinstance(f, dict) and f.get("type") == "SOLID" and "color" in f:
                style["bg"] = to_hex(f["color"])
                if "opacity" in f and f["opacity"] < 1:
                    style["bgOp"] = round(f["opacity"], 2)
                break
    
    # Border (first stroke only)
    strokes = node.get("strokes", [])
    if isinstance(strokes, list) and len(strokes) > 0:
        for s in strokes:
            if isinstance(s, dict) and s.get("type") == "SOLID" and "color" in s:
                b = {"c": to_hex(s["color"])}
                if "strokeWeight" in node:
                    b["w"] = round(float(node["strokeWeight"]), 1)
                style["border"] = b
                break
    
    # Corner radius
    if isinstance(node.get("cornerRadius"), (int, float)) and node.get("cornerRadius", 0) > 0:
        style["radius"] = round(float(node["cornerRadius"]), 1)
    
    # Shadow/effects (only first drop shadow)
    effects = node.get("effects", [])
    if isinstance(effects, list):
        for e in effects:
            if isinstance(e, dict) and e.get("type") == "DROP_SHADOW" and e.get("visible", True):
                off = e.get("offset", {})
                shadow = {
                    "x": round(off.get("x", 0), 1),
                    "y": round(off.get("y", 0), 1),
                    "blur": round(e.get("radius", 0), 1)
                }
                if "color" in e:
                    shadow["c"] = to_hex(e["color"])
                style["shadow"] = shadow
                break
    
    # Opacity
    if "opacity" in node and node["opacity"] < 1:
        style["op"] = round(node["opacity"], 2)
    
    return style if style else None

def extract_essential_text(node: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """Extract essential text properties only"""
    if (node.get("type") or "").upper() != "TEXT":
        return None
    
    text = {"val": node.get("characters", "")}
    
    # Typography
    style = node.get("style", {})
    if isinstance(style, dict):
        typo = {}
        if "fontFamily" in style: typo["family"] = style["fontFamily"]
        if "fontSize" in style: typo["size"] = round(float(style["fontSize"]), 1)
        if "fontWeight" in style: typo["weight"] = style["fontWeight"]
        if "lineHeightPx" in style: typo["lh"] = round(float(style["lineHeightPx"]), 1)
        elif "lineHeight" in style and isinstance(style["lineHeight"], dict):
            if style["lineHeight"].get("value"):
                typo["lh"] = round(float(style["lineHeight"]["value"]), 1)
        if "letterSpacing" in style: typo["ls"] = round(float(style["letterSpacing"]), 2)
        if "textAlignHorizontal" in style: typo["align"] = style["textAlignHorizontal"].lower()
        if typo: text["typo"] = typo
    
    # Color (first fill only)
    fills = node.get("fills", [])
    if isinstance(fills, list):
        for f in fills:
            if isinstance(f, dict) and f.get("type") == "SOLID" and "color" in f:
                text["color"] = to_hex(f["color"])
                break
    
    return text

def should_extract(node: Dict[str, Any]) -> bool:
    """Determine if node is essential for UI recreation"""
    t = (node.get("type") or "").upper()
    name = (node.get("name") or "").lower()
    
    # Always extract text
    if t == 'TEXT':
        return True
    
    # Semantic components
    semantic_keywords = ['button', 'input', 'field', 'nav', 'menu', 'card', 'panel', 
                         'header', 'footer', 'container', 'wrapper', 'box', 'list', 'item']
    if any(k in name for k in semantic_keywords):
        return True
    
    # Has visual properties
    if node.get("fills") or node.get("strokes") or node.get("effects"):
        return True
    
    # Layout containers
    if node.get("layoutMode") or t in ['FRAME', 'COMPONENT', 'INSTANCE', 'GROUP']:
        return True
    
    # Has corner radius
    if isinstance(node.get("cornerRadius"), (int, float)) and node.get("cornerRadius", 0) > 0:
        return True
    
    # Vector shapes with styles
    if t in ['RECTANGLE', 'ELLIPSE', 'VECTOR', 'LINE', 'POLYGON'] and (node.get("fills") or node.get("strokes")):
        return True
    
    return False

def extract_minimal_components(root: Dict[str, Any], parent: str = "", depth: int = 0, out: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
    """Extract only essential component data - maximum compression"""
    if out is None:
        out = []
    if root is None or not isinstance(root, dict) or depth > 50:  # Prevent infinite recursion
        return out
    
    if not should_extract(root):
        # Still traverse children
        for child in root.get('children', []) or []:
            if isinstance(child, dict):
                extract_minimal_components(child, parent, depth + 1, out)
        return out
    
    # Minimal component structure
    comp: Dict[str, Any] = {
        'id': root.get('id'),
        'name': root.get('name'),
        'type': root.get('type')
    }
    
    # Position & dimensions
    bounds = extract_essential_bounds(root)
    if bounds:
        comp['pos'] = bounds
    
    # Layout
    layout = extract_essential_layout(root)
    if layout:
        comp['layout'] = layout
    
    # Styling
    style = extract_essential_style(root)
    if style:
        comp['style'] = style
    
    # Image URL
    if root.get('image_url'):
        comp['img'] = root.get('image_url')
    
    # Text
    text = extract_essential_text(root)
    if text:
        comp['text'] = text
    
    out.append(comp)
    
    # Traverse children
    for child in root.get('children', []) or []:
        if isinstance(child, dict):
            extract_minimal_components(child, root.get('name', ''), depth + 1, out)
    
    return out

def find_document_roots(nodes_payload: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Find all document roots"""
    roots: List[Dict[str, Any]] = []
    if isinstance(nodes_payload.get('nodes'), dict):
        for v in nodes_payload['nodes'].values():
            if isinstance(v, dict) and isinstance(v.get('document'), dict):
                roots.append(v['document'])
        if roots:
            return roots
    if isinstance(nodes_payload.get('document'), dict):
        roots.append(nodes_payload['document'])
    return roots

def extract_ui_components_optimized(merged_payload: Dict[str, Any]) -> Dict[str, Any]:
    """Extract components with minimal metadata for AI agents"""
    roots = find_document_roots(merged_payload)
    if not roots:
        raise RuntimeError("No document roots found")
    
    components: List[Dict[str, Any]] = []
    for r in roots:
        if isinstance(r, dict):
            extract_minimal_components(r, "", 0, components)
    
    # Minimal metadata
    return {
        'meta': {
            'total': len(components),
            'ts': datetime.datetime.utcnow().isoformat()[:19] + 'Z'
        },
        'components': components
    }

def remove_url_prefix_from_json(payload: Dict[str, Any], url_prefix: str) -> Dict[str, Any]:
    """Remove URL prefix for portability"""
    p = copy.deepcopy(payload)
    def process(obj: Any):
        if isinstance(obj, dict):
            for k, v in list(obj.items()):
                if k in ("img", "image_url") and isinstance(v, str):
                    if v.startswith(url_prefix):
                        obj[k] = v.replace(url_prefix, "", 1)
                else:
                    process(v)
        elif isinstance(obj, list):
            for item in obj:
                process(item)
    process(p)
    return p

# -------------------------
# ANGULAR CODE PROCESSING
# -------------------------

UUID_RE = r"[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}"

def add_url_prefix_to_angular_code(text: str, url_prefix: str) -> Tuple[str, int]:
    """Add URL prefix to UUIDs in Angular code"""
    patterns = [
        (re.compile(r'(src\s*=\s*["\'])(%s)(["\'])' % UUID_RE, re.IGNORECASE), r'\1' + url_prefix + r'\2\3'),
        (re.compile(r'(\[src\]\s*=\s*["\']\s*)(%s)(["\'])' % UUID_RE, re.IGNORECASE), r'\1' + url_prefix + r'\2\3'),
        (re.compile(r'(imageUrl\s*:\s*["\'])(%s)(["\'])' % UUID_RE, re.IGNORECASE), r'\1' + url_prefix + r'\2\3'),
        (re.compile(r'(url\(\s*["\'])(%s)(["\']\s*\))' % UUID_RE, re.IGNORECASE), r'\1' + url_prefix + r'\2\3'),
        (re.compile(r'(["\'])(%s)(["\'])' % UUID_RE, re.IGNORECASE), r'\1' + url_prefix + r'\2\3'),
    ]

    modified = text
    total = 0
    for pat, repl in patterns:
        modified, n = pat.subn(repl, modified)
        total += n
    return modified, total

def create_text_to_pdf(text_content: str) -> BytesIO:
    """Convert text to PDF"""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter, topMargin=0.5*inch, bottomMargin=0.5*inch, 
                           leftMargin=0.5*inch, rightMargin=0.5*inch)
    styles = getSampleStyleSheet()
    code_style = ParagraphStyle('Code', parent=styles.get('Normal'), fontName='Courier', 
                                fontSize=8, leading=10, spaceAfter=6)
    story = []
    lines = text_content.splitlines()
    chunk_size = 60
    for i in range(0, len(lines), chunk_size):
        block = lines[i:i+chunk_size]
        safe = [ln.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;') for ln in block]
        story.append(Paragraph('<br/>'.join(safe), code_style))
    doc.build(story)
    buffer.seek(0)
    return buffer

def detect_uuids_in_text(text: str) -> List[str]:
    """Detect unique UUIDs"""
    pattern = re.compile(UUID_RE, re.IGNORECASE)
    found = pattern.findall(text)
    seen = set()
    out = []
    for f in found:
        if f not in seen:
            seen.add(f)
            out.append(f)
    return out

def decode_bytes_to_text(raw: bytes) -> str:
    """Decode bytes to text"""
    try:
        return raw.decode('utf-8')
    except:
        try:
            return raw.decode('latin-1')
        except:
            return raw.decode('utf-8', errors='ignore')

# -------------------------
# STREAMLIT UI
# -------------------------

def main():
    st.markdown("""
    <div style='text-align: center; padding: 1rem 0 2rem 0;'>
        <h1 style='margin-bottom: 0.5rem;'>üé® Figma UI Extractor</h1>
        <p style='font-size: 1.05rem; color: #6B7280; font-weight: 500;'>
            Token-Optimized Extraction for AI Agent Processing
        </p>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.markdown("### ‚öôÔ∏è System Information")
        st.markdown("---")

        if 'stats' not in st.session_state:
            st.session_state['stats'] = {'files_processed': 0, 'downloads': 0, 'token_saved': 0}

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Files Processed", st.session_state['stats']['files_processed'])
        with col2:
            st.metric("Downloads", st.session_state['stats']['downloads'])
        
        if st.session_state['stats']['token_saved'] > 0:
            st.metric("Tokens Saved", f"{st.session_state['stats']['token_saved']}%")

        st.markdown("---")
        st.markdown("### üìö Resources")
        st.markdown("""
        - [Figma API Docs](https://www.figma.com/developers/api)
        - [Angular Material](https://material.angular.io)
        """)
        st.markdown("---")
        st.info("‚ú® **Optimized** for minimal token usage (~70% reduction)")

    tab1, tab2 = st.tabs(["üéØ Figma Extraction", "‚ö° Angular Processor"])

    with tab1:
        st.markdown("### Token-Optimized Component Extraction")
        st.markdown("Extracts only **essential** properties needed for 100% UI recreation with minimal tokens.")
        st.markdown("---")

        col1, col2 = st.columns(2)
        with col1:
            file_key = st.text_input("üìÅ Figma File Key", value="", help="From Figma file URL")
        with col2:
            node_ids = st.text_input("üîó Node IDs (optional)", value="", help="Comma-separated")

        token = st.text_input("üîë Figma Access Token", type="password")

        if st.button("üöÄ Extract Essential UI Data"):
            if not token or not file_key:
                st.error("‚ö†Ô∏è Please provide file key and token")
            else:
                try:
                    progress = st.progress(0)
                    status = st.empty()

                    status.text("üì° Fetching nodes...")
                    progress.progress(10)
                    nodes_payload = fetch_figma_nodes(file_key=file_key, node_ids=node_ids, token=token)

                    status.text("üñºÔ∏è Collecting images...")
                    progress.progress(30)
                    image_refs, node_id_list = walk_nodes_collect_images_and_ids(nodes_payload)

                    status.text("üîó Resolving image URLs...")
                    progress.progress(50)
                    fills_map = resolve_image_urls(file_key, image_refs, token)

                    status.text("üé® Merging data...")
                    progress.progress(70)
                    merged_payload = merge_urls_into_nodes(nodes_payload, fills_map)

                    status.text("üì¶ Extracting minimal components...")
                    progress.progress(85)
                    final_output = extract_ui_components_optimized(merged_payload)

                    status.text("‚ú® Finalizing...")
                    progress.progress(95)
                    sanitized = remove_url_prefix_from_json(final_output, "https://figma-alpha-api.s3.us-west-2.amazonaws.com/images/")
                    
                    # Calculate size
                    json_str = json.dumps(sanitized, separators=(',', ':'), ensure_ascii=False)
                    size_kb = len(json_str) / 1024
                    
                    st.session_state['metadata_json'] = sanitized
                    st.session_state['json_size'] = size_kb
                    st.session_state['stats']['files_processed'] += 1
                    st.session_state['stats']['token_saved'] = 70  # Approx 70% reduction
                    
                    progress.progress(100)
                    st.success(f"‚úÖ Extraction complete! Payload size: **{size_kb:.1f} KB**")

                    # Metrics
                    st.markdown("### üìä Extraction Summary")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Components", sanitized['meta']['total'])
                    with col2:
                        st.metric("Images", len(image_refs))
                    with col3:
                        st.metric("Size", f"{size_kb:.1f} KB")
                    with col4:
                        token_est = int(size_kb * 4)  # Rough estimate: 1KB ‚âà 4 tokens
                        st.metric("Est. Tokens", f"~{token_est}")
                    
                    if size_kb < 25:
                        st.success("‚úÖ Payload is under 25KB - optimal for AI agents!")
                    else:
                        st.warning(f"‚ö†Ô∏è Payload is {size_kb:.1f}KB. Consider extracting specific nodes only.")

                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")

        if 'metadata_json' in st.session_state:
            st.markdown("---")
            st.markdown("### üíæ Download Extracted Data")
            json_str = json.dumps(st.session_state['metadata_json'], indent=2, ensure_ascii=False)
            json_compact = json.dumps(st.session_state['metadata_json'], separators=(',', ':'), ensure_ascii=False)

            col1, col2, col3 = st.columns(3)
            with col1:
                st.download_button(
                    "üì• Readable JSON (indented)",
                    data=json_str,
                    file_name="ui_metadata.json",
                    mime="application/json",
                    on_click=lambda: st.session_state['stats'].update({'downloads': st.session_state['stats']['downloads'] + 1})
                )
            with col2:
                st.download_button(
                    "üì¶ Compact JSON (minimal)",
                    data=json_compact,
                    file_name="ui_metadata_compact.json",
                    mime="application/json",
                    on_click=lambda: st.session_state['stats'].update({'downloads': st.session_state['stats']['downloads'] + 1})
                )
            with col3:
                st.caption(f"Readable: {len(json_str)/1024:.1f} KB\nCompact: {len(json_compact)/1024:.1f} KB")
            
            with st.expander("üìã View JSON Preview"):
                st.json(st.session_state['metadata_json'], expanded=False)

    with tab2:
        st.markdown("### Angular Code Image URL Processor")
        st.markdown("Prefix UUID image IDs with full URLs")
        st.markdown("---")

        url_prefix = st.text_input(
            "üåê URL Prefix",
            value="https://figma-alpha-api.s3.us-west-2.amazonaws.com/images/",
            help="Prefix for image UUIDs"
        )

        input_method = st.radio(
            "Input Method:",
            options=["üì§ Upload File", "üìù Paste Code"],
            horizontal=True
        )

        code_text = ""
        source_filename = "code"

        if input_method == "üì§ Upload File":
            uploaded = st.file_uploader(
                "üì§ Upload Code File",
                type=['txt', 'md', 'html', 'ts', 'js', 'css', 'scss', 'json']
            )

            if uploaded:
                st.info(f"‚úÖ File: **{uploaded.name}**")
                try:
                    raw = uploaded.read()
                    code_text = decode_bytes_to_text(raw)
                    source_filename = uploaded.name.rsplit('.', 1)[0] if '.' in uploaded.name else uploaded.name
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")
        else:
            code_text = st.text_area(
                "üìù Paste Code",
                height=320,
                placeholder="Paste TypeScript/HTML/CSS code..."
            )
            source_filename = "pasted_code"

        if code_text and code_text.strip():
            if st.button("‚ö° Process Code", type="primary"):
                try:
                    uuids = detect_uuids_in_text(code_text)
                    modified, replaced = add_url_prefix_to_angular_code(code_text, url_prefix)

                    st.session_state['angular_output'] = modified
                    st.session_state['angular_filename'] = source_filename
                    st.session_state['stats']['files_processed'] += 1

                    st.success("‚úÖ Code processed!")

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("UUIDs Found", len(uuids))
                    with col2:
                        st.metric("Replacements", replaced)
                    with col3:
                        st.metric("Output Size", f"{len(modified):,} bytes")

                    if len(uuids) > 0:
                        with st.expander("üîç Sample"):
                            sample = uuids[0]
                            st.code(f"Before: {sample}", language="text")
                            st.code(f"After: {url_prefix}{sample}", language="text")
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")

        if 'angular_output' in st.session_state:
            st.markdown("---")
            st.markdown("### üíæ Download Processed Code")
            base = st.session_state['angular_filename']

            st.markdown("#### üíª Copy Code")
            st.code(st.session_state['angular_output'], language="typescript")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.download_button(
                    "üìÑ .txt",
                    data=st.session_state['angular_output'],
                    file_name=f"{base}_processed.txt",
                    mime="text/plain",
                    on_click=lambda: st.session_state['stats'].update({'downloads': st.session_state['stats']['downloads'] + 1})
                )
            with col2:
                st.download_button(
                    "üìù .md",
                    data=st.session_state['angular_output'],
                    file_name=f"{base}_processed.md",
                    mime="text/markdown",
                    on_click=lambda: st.session_state['stats'].update({'downloads': st.session_state['stats']['downloads'] + 1})
                )
            with col3:
                st.download_button(
                    "üíª .ts",
                    data=st.session_state['angular_output'],
                    file_name=f"{base}_processed.ts",
                    mime="text/typescript",
                    on_click=lambda: st.session_state['stats'].update({'downloads': st.session_state['stats']['downloads'] + 1})
                )
            with col4:
                pdf_buf = create_text_to_pdf(st.session_state['angular_output'])
                st.download_button(
                    "üìï .pdf",
                    data=pdf_buf,
                    file_name=f"{base}_processed.pdf",
                    mime="application/pdf",
                    on_click=lambda: st.session_state['stats'].update({'downloads': st.session_state['stats']['downloads'] + 1})
                )

    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; padding: 1.5rem 0; color: #6B7280;'>
        <p style='margin: 0; font-size: 0.9rem;'>Built with ‚ù§Ô∏è | Token-Optimized Edition</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
